{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "%run ML_Record_Mining_JN.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-495ad43fae3b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# Options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchained_assignment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# Loading libraries for modeling\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import time\n",
    "\n",
    "import os\n",
    "path = r'/Users/seiryu8808/Desktop/UWinsc/Github/UnacquiredSites/src/output'\n",
    "\n",
    "# Options\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Modeling for Latitude and Longitude Coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to encode the text data into vectors in order to apply a Classification algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = nlp_bib_neotoma[['_gddid', 'sentid', 'words', 'words_as_string', 'dms_regex', 'dd_regex', 'latnorth', 'longeast', 'intersection_words_lat', 'intersection_words_long']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         Available online at www.sciencedirect.com Quat...\n",
       "1         The Chihuahueños Bog record extends to over 15...\n",
       "2         An Artemisia steppe, then an open Picea woodla...\n",
       "3         C/N ratios, δ13C and δ15N values indicate both...\n",
       "4         Higher percentages of aquatic algae and elevat...\n",
       "                                ...                        \n",
       "106635                                                Ann .\n",
       "106636                                        Sofia Univ. .\n",
       "106637                                                Fac .\n",
       "106638                                               Geol .\n",
       "106639    Geogr85, 181198 (in Bulgarian with English sum...\n",
       "Name: words_as_string, Length: 106640, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['words_as_string']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['has_both_lat_long_int'] = ((data['intersection_words_lat'].apply(len) != 0) & (data['intersection_words_long'].apply(len) != 0 ))\n",
    "\n",
    "# Map True to One and False to Zero\n",
    "data['has_both_lat_long_int'] = data['has_both_lat_long_int'].astype(int)\n",
    "\n",
    "# Reduce data to columns of interest for this task.\n",
    "data = data[['words_as_string', 'has_both_lat_long_int']]\n",
    "\n",
    "# Define corpus for CountVectorizer\n",
    "corpus = data['words_as_string'].tolist()\n",
    "\n",
    "# Split data into training and testing sets\n",
    "data_train, data_test = train_test_split(data, test_size = 0.20, random_state = 12)\n",
    "\n",
    "# Translate words to vectors\n",
    "# This model can add stopwords, punctuation, etc.\n",
    "# For now, use all words.\n",
    "vec = CountVectorizer(min_df=2, \n",
    "                      tokenizer=nltk.word_tokenize)\n",
    "\n",
    "# Fit and transform training\n",
    "X_train = vec.fit_transform(data_train['words_as_string']) \n",
    "y_train = data_train['has_both_lat_long_int']\n",
    "\n",
    "# Transform test data without fitting\n",
    "X_test = vec.transform(data_test['words_as_string']) \n",
    "y_test = data_test['has_both_lat_long_int']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to fit into different models to see which one renders the best performance. Take into consideration that this model will eventually be escalated to a bigger amount of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = {\n",
    "#    'knn'           : KNeighborsClassifier(),\n",
    "    'decision tree' : DecisionTreeClassifier(random_state = 0, max_depth = 15),\n",
    "    'random forest' : RandomForestClassifier(n_estimators = 10)\n",
    "#    'SVM'           : SVC(C = 100, gamma = \"scale\"),\n",
    "#    'logistic reg'  : LogisticRegression(solver=\"lbfgs\", max_iter = 10000)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_scores(classifiers = classifiers, X_train = X_train, y_train = y_train, X_test = X_test, y_test = y_test):\n",
    "    train_scores = dict()\n",
    "    test_scores = dict()\n",
    "    training_times = dict()\n",
    "\n",
    "    for classifier_name, classifier_obj in classifiers.items():\n",
    "     #   print(\"Fitting\", classifier_name)\n",
    "        t = time.time()\n",
    "        classifier_obj.fit(X_train, y_train)\n",
    "\n",
    "        training_times[classifier_name] = time.time() - t\n",
    "        train_scores[classifier_name] = classifier_obj.score(X_train, y_train)\n",
    "        test_scores[classifier_name] = classifier_obj.score(X_test, y_test)\n",
    "\n",
    "    data = {\"train acc\": train_scores, \"valid acc\" : test_scores, \"training time (s)\" : training_times}\n",
    "    df = pd.DataFrame(data, columns = data.keys())\n",
    "    df.index = list(classifiers.keys())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train acc</th>\n",
       "      <th>valid acc</th>\n",
       "      <th>training time (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>decision tree</td>\n",
       "      <td>0.999285</td>\n",
       "      <td>0.997984</td>\n",
       "      <td>0.702710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>random forest</td>\n",
       "      <td>0.999660</td>\n",
       "      <td>0.997703</td>\n",
       "      <td>0.623006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               train acc  valid acc  training time (s)\n",
       "decision tree   0.999285   0.997984           0.702710\n",
       "random forest   0.999660   0.997703           0.623006"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df = create_scores()\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see there is overfitting happening, since all testing scores are too good to be true.   \n",
    "We also have to take into consideration that just 230 sentences have both coordinates out of over 100,000.   \n",
    "With this data unbalance, guessing 0 over all sentences would still be a very high accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking different scores such as confusion matrices\n",
    "\n",
    "From the above matrix, we can see that SVM and Logistic Regression are computationally expensive. Taking into consideration that this experiment will eventually be scaled to a larger data set, let's discard these two methods. \n",
    "\n",
    "One way to know if a method is not missclassifying items, would be to check the confusion matrix and see how many false possitives or false negatives it has."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix decision tree\n",
      "[21266    10    33    19]\n",
      "Confusion Matrix random forest\n",
      "[21276     0    47     5]\n"
     ]
    }
   ],
   "source": [
    "for classifier_name, classifier_obj in classifiers.items():\n",
    "    print(\"Confusion Matrix\", classifier_name)\n",
    "    classifier_obj.fit(X_train, y_train)\n",
    "    y_pred = classifier_obj.predict(X_test)\n",
    "    conf_mat = confusion_matrix(y_test, y_pred).ravel()\n",
    "    print(conf_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the random forest seems to have no false positives, it has 11 more false negatives. True positives are being completely missed. \n",
    "So, although it is faster to train, it is not a good model.\n",
    "\n",
    "Let's then work with Decission Tree classifier and tune it to find the best parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.float_format = '{:,.5f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_size</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.99803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>0.99941</td>\n",
       "      <td>0.99794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>42</td>\n",
       "      <td>0.99916</td>\n",
       "      <td>0.99789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>62</td>\n",
       "      <td>0.99906</td>\n",
       "      <td>0.99794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>82</td>\n",
       "      <td>0.99906</td>\n",
       "      <td>0.99812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>102</td>\n",
       "      <td>0.99907</td>\n",
       "      <td>0.99794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>122</td>\n",
       "      <td>0.99910</td>\n",
       "      <td>0.99812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>142</td>\n",
       "      <td>0.99911</td>\n",
       "      <td>0.99789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>162</td>\n",
       "      <td>0.99899</td>\n",
       "      <td>0.99803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>182</td>\n",
       "      <td>0.99898</td>\n",
       "      <td>0.99798</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sample_size  train_accuracy  test_accuracy\n",
       "0            2         1.00000        0.99803\n",
       "1           22         0.99941        0.99794\n",
       "2           42         0.99916        0.99789\n",
       "3           62         0.99906        0.99794\n",
       "4           82         0.99906        0.99812\n",
       "5          102         0.99907        0.99794\n",
       "6          122         0.99910        0.99812\n",
       "7          142         0.99911        0.99789\n",
       "8          162         0.99899        0.99803\n",
       "9          182         0.99898        0.99798"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_samples_split_dict = {'sample_size':[], 'train_accuracy':[], 'test_accuracy' :[]}\n",
    "\n",
    "for nsamples in range(2,200,20):\n",
    "    model = DecisionTreeClassifier(min_samples_split = nsamples)\n",
    "    model.fit(X_train, y_train)\n",
    "    score = model.score(X_train,y_train)\n",
    "    test_score = model.score(X_test,y_test)\n",
    "    min_samples_split_dict['sample_size'].append(nsamples)    \n",
    "    min_samples_split_dict['train_accuracy'].append(score)\n",
    "    min_samples_split_dict['test_accuracy'].append(test_score)\n",
    "    \n",
    "min_samples_split_df = pd.DataFrame(min_samples_split_dict)\n",
    "min_samples_split_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.99807</td>\n",
       "      <td>0.99780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0.99916</td>\n",
       "      <td>0.99808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>0.99939</td>\n",
       "      <td>0.99812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>0.99951</td>\n",
       "      <td>0.99789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>42</td>\n",
       "      <td>0.99972</td>\n",
       "      <td>0.99794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>52</td>\n",
       "      <td>0.99988</td>\n",
       "      <td>0.99803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>62</td>\n",
       "      <td>0.99998</td>\n",
       "      <td>0.99784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>72</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.99775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>82</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.99775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>92</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.99775</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   max_depth  train_accuracy  test_accuracy\n",
       "0          2         0.99807        0.99780\n",
       "1         12         0.99916        0.99808\n",
       "2         22         0.99939        0.99812\n",
       "3         32         0.99951        0.99789\n",
       "4         42         0.99972        0.99794\n",
       "5         52         0.99988        0.99803\n",
       "6         62         0.99998        0.99784\n",
       "7         72         1.00000        0.99775\n",
       "8         82         1.00000        0.99775\n",
       "9         92         1.00000        0.99775"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_depth_dict = {'max_depth':[], 'train_accuracy':[], 'test_accuracy':[]}\n",
    "\n",
    "for nsamples in range(2,100,10):\n",
    "    model = DecisionTreeClassifier(max_depth = nsamples)\n",
    "    model.fit(X_train, y_train)\n",
    "    score = model.score(X_train,y_train)\n",
    "    test_sc = model.score(X_test, y_test)\n",
    "    max_depth_dict['max_depth'].append(nsamples)    \n",
    "    max_depth_dict['train_accuracy'].append(score)\n",
    "    max_depth_dict['test_accuracy'].append(test_sc)\n",
    "    \n",
    "max_depth_df = pd.DataFrame(max_depth_dict)\n",
    "max_depth_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(min_samples_split = 40, max_depth = 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=12,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=40,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having chosen our hyperparameters, let's examine which features are the most important features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See which features are considered important\n",
    "f_imp = clf.feature_importances_\n",
    "\n",
    "feature_importance = 100.0 * (f_imp / f_imp.max())\n",
    "feature_names = vec.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A holder for feature_name: feature_importance\n",
    "feats = {} \n",
    "for feature, importance in zip(feature_names, feature_importance):\n",
    "    feats[feature] = importance #add the name/value pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fe0de2b5550>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "importances = pd.DataFrame.from_dict(feats, orient='index').rename(columns={0: 'Gini-importance'})\n",
    "importances.sort_values(by='Gini-importance', ascending=False)[:12].plot(kind='bar', rot=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9979838709677419"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([21262,    14,    29,    23])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export csv to compare y_pred and y_test labels\n",
    "guessed_label = pd.DataFrame(y_pred)\n",
    "actual_label = pd.DataFrame(y_test)\n",
    "actual_label = actual_label.reset_index()\n",
    "\n",
    "# Join with sentences\n",
    "original_sentence = pd.DataFrame(data_test['words_as_string'])\n",
    "original_sentence = original_sentence .reset_index()\n",
    "\n",
    "comparison_df = guessed_label.join(actual_label)\n",
    "comparison_df = comparison_df.drop(columns=['index'])\n",
    "\n",
    "comparison_df = comparison_df.join(original_sentence)\n",
    "comparison_df = comparison_df.drop(columns=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = os.path.join(path,'modeled_sentences.tsv')\n",
    "comparison_df.to_csv(output_file, sep='\\t', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the reasons for such a poor classification with the False Negatives, it is because data  is too unbalanced. \n",
    "\n",
    "We are going to address that problem now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balancing DataSet\n",
    "\n",
    "Although usually more data is better, we have a very few number of sentences that satisfy the condition of having \"coordinates\".\n",
    "\n",
    "In order to balance training, I will only take 300 random sentences that have no coordinates. This will be even with sentences that have coordinates and maybe this will create less noise. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = nlp_bib_neotoma[['_gddid', 'sentid', 'words', 'words_as_string', 'dms_regex', 'dd_regex', 'latnorth', 'longeast', 'intersection_words_lat', 'intersection_words_long']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['has_both_lat_long_int'] = ((data['intersection_words_lat'].apply(len) != 0) & (data['intersection_words_long'].apply(len) != 0 ))\n",
    "\n",
    "# Map True to One and False to Zero\n",
    "data['has_both_lat_long_int'] = data['has_both_lat_long_int'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce data to columns of interest\n",
    "data = data[['words_as_string', 'has_both_lat_long_int']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words_as_string</th>\n",
       "      <th>has_both_lat_long_int</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>51694</td>\n",
       "      <td>DOI : 10.111 / j.1365-2699 .2010.0238 .</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>83952</td>\n",
       "      <td>On the other hand, laminated sediments (varves...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         words_as_string  \\\n",
       "51694            DOI : 10.111 / j.1365-2699 .2010.0238 .   \n",
       "83952  On the other hand, laminated sediments (varves...   \n",
       "\n",
       "       has_both_lat_long_int  \n",
       "51694                      0  \n",
       "83952                      0  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from random import shuffle\n",
    "data0 = data[data['has_both_lat_long_int'] == 0]\n",
    "data0 = data0.sample(n = 300)\n",
    "data1 = data[data['has_both_lat_long_int'] == 1]\n",
    "data = pd.concat([data0, data1])\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define corpus for CountVectorizer\n",
    "corpus = data['words_as_string'].tolist()\n",
    "\n",
    "# Split data into training and testing sets\n",
    "data_train, data_test = train_test_split(data, test_size = 0.20, random_state = 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Translate words to vectors\n",
    "# This model can add stopwords, punctuation, etc.\n",
    "# For now, use all words.\n",
    "vec = CountVectorizer(min_df=2, \n",
    "                      tokenizer=nltk.word_tokenize)\n",
    "\n",
    "# Fit and transform training\n",
    "X_train = vec.fit_transform(data_train['words_as_string']) \n",
    "y_train = data_train['has_both_lat_long_int']\n",
    "\n",
    "# Transform test data without fitting\n",
    "X_test = vec.transform(data_test['words_as_string']) \n",
    "y_test = data_test['has_both_lat_long_int']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using same model since we are just comparing 'Data Balancing'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=12,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=40,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8679245283018868"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9457547169811321"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00473934, 0.37931034, 1.        , 1.        , 0.00473934,\n",
       "       0.00473934, 0.37931034, 0.00473934, 0.00473934, 0.37931034,\n",
       "       0.00473934, 0.00473934, 0.42857143, 0.00473934, 1.        ,\n",
       "       1.        , 1.        , 1.        , 0.00473934, 0.37931034,\n",
       "       1.        , 1.        , 1.        , 0.00473934, 0.94594595,\n",
       "       0.00473934, 0.42857143, 0.37931034, 1.        , 1.        ,\n",
       "       0.37931034, 1.        , 1.        , 0.00473934, 0.77272727,\n",
       "       0.94594595, 0.00473934, 0.37931034, 1.        , 0.00473934,\n",
       "       1.        , 0.00473934, 0.37931034, 0.00473934, 1.        ,\n",
       "       0.94594595, 0.42857143, 1.        , 0.77272727, 0.94594595,\n",
       "       0.77272727, 0.00473934, 0.77272727, 0.00473934, 0.77272727,\n",
       "       1.        , 1.        , 0.77272727, 0.00473934, 1.        ,\n",
       "       0.00473934, 1.        , 1.        , 0.00473934, 0.77272727,\n",
       "       1.        , 0.00473934, 0.00473934, 0.77272727, 0.00473934,\n",
       "       1.        , 0.94594595, 0.00473934, 0.00473934, 0.77272727,\n",
       "       0.94594595, 0.00473934, 0.00473934, 0.00473934, 0.42857143,\n",
       "       0.94594595, 0.00473934, 0.77272727, 0.00473934, 0.00473934,\n",
       "       0.00473934, 0.00473934, 1.        , 0.37931034, 0.00473934,\n",
       "       0.00473934, 1.        , 0.00473934, 0.94594595, 0.42857143,\n",
       "       0.00473934, 1.        , 0.94594595, 0.00473934, 1.        ,\n",
       "       0.37931034, 0.00473934, 0.94594595, 0.00473934, 1.        ,\n",
       "       0.00473934])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "filename = 'finalized_model.sav'\n",
    "pickle.dump(clf, open(filename, 'wb'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8679245283018868\n"
     ]
    }
   ],
   "source": [
    "# load the model from disk\n",
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "result = loaded_model.score(X_test, y_test)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See which features are considered important\n",
    "f_imp = clf.feature_importances_\n",
    "feature_importance = 100.0 * (f_imp / f_imp.max())\n",
    "feature_names = vec.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A holder for feature_name: feature_importance\n",
    "feats = {} \n",
    "for feature, importance in zip(feature_names, feature_importance):\n",
    "    feats[feature] = importance #add the name/value pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fe0dbe112d0>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "importances = pd.DataFrame.from_dict(feats, orient='index').rename(columns={0: 'Gini-importance'})\n",
    "importances.sort_values(by='Gini-importance', ascending=False)[:12].plot(kind='bar', rot=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gini-importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>m</td>\n",
       "      <td>100.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>n</td>\n",
       "      <td>52.09199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>)</td>\n",
       "      <td>28.59326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>8.94209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>km</td>\n",
       "      <td>6.91247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>2.61247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>2.58794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>polylepis</td>\n",
       "      <td>2.56988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>communities</td>\n",
       "      <td>2.51849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>water</td>\n",
       "      <td>2.46862</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Gini-importance\n",
       "m                  100.00000\n",
       "n                   52.09199\n",
       ")                   28.59326\n",
       "41                   8.94209\n",
       "km                   6.91247\n",
       "...                      ...\n",
       "74                   2.61247\n",
       "76                   2.58794\n",
       "polylepis            2.56988\n",
       "communities          2.51849\n",
       "water                2.46862\n",
       "\n",
       "[15 rows x 1 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importances.sort_values(by='Gini-importance', ascending = False)[0:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([50,  7,  7, 42])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "confusion_matrix(y_test, y_pred).ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that we have improved significantly the percentage of True Positives and True Negatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred = clf.predict(X_test)\n",
    "mse = sum((Y_pred - y_test)**2)\n",
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "guessed_label = pd.DataFrame(Y_pred)\n",
    "actual_label = pd.DataFrame(y_test)\n",
    "actual_label = actual_label.reset_index()\n",
    "\n",
    "original_sentence = pd.DataFrame(data_test['words_as_string'])\n",
    "original_sentence = original_sentence .reset_index()\n",
    "\n",
    "comp_guessed_test_sm = guessed_label.join(actual_label)\n",
    "comp_guessed_test_sm = comp_guessed_test_sm.drop(columns=['index'])\n",
    "\n",
    "comp_guessed_test_sm = comp_guessed_test_sm.join(original_sentence)\n",
    "comp_guessed_test_sm = comp_guessed_test_sm.drop(columns=['index'])\n",
    "# comp_guessed_test_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "output_file = os.path.join(path,'small_model_sentences.tsv')\n",
    "comp_guessed_test_sm.to_csv(output_file, sep='\\t', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion for now:\n",
    "\n",
    "Use a Tree Classifier with a max depth of 12."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes: What about Word2Vec or GloVe embeddings?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'/Users/seiryu8808/Desktop'\n",
    "data_file = r'preprocessed_sentences.tsv'\n",
    "\n",
    "file = r'/Users/seiryu8808/Desktop/preprocessed_sentences.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(file, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_gddid</th>\n",
       "      <th>sentid</th>\n",
       "      <th>words</th>\n",
       "      <th>words_as_string</th>\n",
       "      <th>link_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>54b43266e138239d8684efed</td>\n",
       "      <td>1</td>\n",
       "      <td>['Available', 'online', 'at', 'www.sciencedire...</td>\n",
       "      <td>Available online at www.sciencedirect.com Quat...</td>\n",
       "      <td>http://www.sciencedirect.com/science/article/p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>54b43266e138239d8684efed</td>\n",
       "      <td>2</td>\n",
       "      <td>['The', 'Chihuahueños', 'Bog', 'record', 'exte...</td>\n",
       "      <td>The Chihuahueños Bog record extends to over 15...</td>\n",
       "      <td>http://www.sciencedirect.com/science/article/p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>54b43266e138239d8684efed</td>\n",
       "      <td>3</td>\n",
       "      <td>['An', 'Artemisia', 'steppe', ',', 'then', 'an...</td>\n",
       "      <td>An Artemisia steppe, then an open Picea woodla...</td>\n",
       "      <td>http://www.sciencedirect.com/science/article/p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>54b43266e138239d8684efed</td>\n",
       "      <td>4</td>\n",
       "      <td>['C/N', 'ratios', ',', 'δ13C', 'and', 'δ15N', ...</td>\n",
       "      <td>C/N ratios, δ13C and δ15N values indicate both...</td>\n",
       "      <td>http://www.sciencedirect.com/science/article/p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>54b43266e138239d8684efed</td>\n",
       "      <td>5</td>\n",
       "      <td>['Higher', 'percentages', 'of', 'aquatic', 'al...</td>\n",
       "      <td>Higher percentages of aquatic algae and elevat...</td>\n",
       "      <td>http://www.sciencedirect.com/science/article/p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>111960</td>\n",
       "      <td>58d29193cf58f14928755ba5</td>\n",
       "      <td>80</td>\n",
       "      <td>['Ann', '.']</td>\n",
       "      <td>Ann .</td>\n",
       "      <td>http://www.tandfonline.com/doi/abs/10.1080/001...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>111961</td>\n",
       "      <td>58d29193cf58f14928755ba5</td>\n",
       "      <td>81</td>\n",
       "      <td>['Sofia', 'Univ.', '.']</td>\n",
       "      <td>Sofia Univ. .</td>\n",
       "      <td>http://www.tandfonline.com/doi/abs/10.1080/001...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>111962</td>\n",
       "      <td>58d29193cf58f14928755ba5</td>\n",
       "      <td>82</td>\n",
       "      <td>['Fac', '.']</td>\n",
       "      <td>Fac .</td>\n",
       "      <td>http://www.tandfonline.com/doi/abs/10.1080/001...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>111963</td>\n",
       "      <td>58d29193cf58f14928755ba5</td>\n",
       "      <td>83</td>\n",
       "      <td>['Geol', '.']</td>\n",
       "      <td>Geol .</td>\n",
       "      <td>http://www.tandfonline.com/doi/abs/10.1080/001...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>111964</td>\n",
       "      <td>58d29193cf58f14928755ba5</td>\n",
       "      <td>84</td>\n",
       "      <td>['Geogr.', ',', '85', ',', '181', '--', '198',...</td>\n",
       "      <td>Geogr85, 181198 (in Bulgarian with English sum...</td>\n",
       "      <td>http://www.tandfonline.com/doi/abs/10.1080/001...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>111965 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          _gddid  sentid  \\\n",
       "0       54b43266e138239d8684efed       1   \n",
       "1       54b43266e138239d8684efed       2   \n",
       "2       54b43266e138239d8684efed       3   \n",
       "3       54b43266e138239d8684efed       4   \n",
       "4       54b43266e138239d8684efed       5   \n",
       "...                          ...     ...   \n",
       "111960  58d29193cf58f14928755ba5      80   \n",
       "111961  58d29193cf58f14928755ba5      81   \n",
       "111962  58d29193cf58f14928755ba5      82   \n",
       "111963  58d29193cf58f14928755ba5      83   \n",
       "111964  58d29193cf58f14928755ba5      84   \n",
       "\n",
       "                                                    words  \\\n",
       "0       ['Available', 'online', 'at', 'www.sciencedire...   \n",
       "1       ['The', 'Chihuahueños', 'Bog', 'record', 'exte...   \n",
       "2       ['An', 'Artemisia', 'steppe', ',', 'then', 'an...   \n",
       "3       ['C/N', 'ratios', ',', 'δ13C', 'and', 'δ15N', ...   \n",
       "4       ['Higher', 'percentages', 'of', 'aquatic', 'al...   \n",
       "...                                                   ...   \n",
       "111960                                       ['Ann', '.']   \n",
       "111961                            ['Sofia', 'Univ.', '.']   \n",
       "111962                                       ['Fac', '.']   \n",
       "111963                                      ['Geol', '.']   \n",
       "111964  ['Geogr.', ',', '85', ',', '181', '--', '198',...   \n",
       "\n",
       "                                          words_as_string  \\\n",
       "0       Available online at www.sciencedirect.com Quat...   \n",
       "1       The Chihuahueños Bog record extends to over 15...   \n",
       "2       An Artemisia steppe, then an open Picea woodla...   \n",
       "3       C/N ratios, δ13C and δ15N values indicate both...   \n",
       "4       Higher percentages of aquatic algae and elevat...   \n",
       "...                                                   ...   \n",
       "111960                                              Ann .   \n",
       "111961                                      Sofia Univ. .   \n",
       "111962                                              Fac .   \n",
       "111963                                             Geol .   \n",
       "111964  Geogr85, 181198 (in Bulgarian with English sum...   \n",
       "\n",
       "                                                 link_url  \n",
       "0       http://www.sciencedirect.com/science/article/p...  \n",
       "1       http://www.sciencedirect.com/science/article/p...  \n",
       "2       http://www.sciencedirect.com/science/article/p...  \n",
       "3       http://www.sciencedirect.com/science/article/p...  \n",
       "4       http://www.sciencedirect.com/science/article/p...  \n",
       "...                                                   ...  \n",
       "111960  http://www.tandfonline.com/doi/abs/10.1080/001...  \n",
       "111961  http://www.tandfonline.com/doi/abs/10.1080/001...  \n",
       "111962  http://www.tandfonline.com/doi/abs/10.1080/001...  \n",
       "111963  http://www.tandfonline.com/doi/abs/10.1080/001...  \n",
       "111964  http://www.tandfonline.com/doi/abs/10.1080/001...  \n",
       "\n",
       "[111965 rows x 5 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
